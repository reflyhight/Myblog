title: Kafka 文档（一）简介
tags: 
	- mq
	- kafka

categories:
	- 大数据
-------------------

>本文大致翻译kafka官网 [Getting Started](http://kafka.apache.org/documentation/#gettingStarted)，部分细节加入个人理解。**Getting Started**让你理解kafka的相关概念。

###    kafka是分布式流处理平台，那么它确切的有什么作用?
作为流处理平台，那么它应该具备三个关键的作用
- 1.让你发布和订阅流式数据，这样看来，它更像是消息队列或者说企业级消息系统
- 2.让你存储的流数据记录具有容错机制
- 3.让你可以较实时的记录产生的流数据
 
###    什么场景适用于使用kafka呢？
大致最适合两大类场景使用
 
- 1.作为实时流处理通道，建立应用或者系统之间的消息桥梁
- 2.创建实时流系统（监控系统），可以反映数据的状况
 
为了了解kafka如何实现这些功能的，我们由上往下深入的学习kafka的这些功能(dive in from the bottom up不知道是不是从架构到底层实现的意思)。
 
首先让我明确一下一些概念：
- kafka通常是作为分布式集群使用，由一个或多个服务构成的分布式系统
- kafka集群存储的数据是分类别的，这种类别的概念就叫topics
- kafka中的每条数据都包含一个key和一个value，还有一个时间戳
 
kafka目前拥有4部分核心的API:
- **Producer API**    可以发布数据到一个或者多个topic中
- **Consumer API**    可以订阅和处理一个或者多个topic的消息
- **Streams API**    可以作为一个流处理器使用，使用这个流处理器，能将一个或者多个topic中的数据作为输入，处理后再输出到一个或者topic中
- **Connector API**    可以构建可重复利用的producers 或者 consumers，可以很方便将topic中的数据和应用或者文件系统交互

<img src="http://ou9e0q35h.bkt.clouddn.com/kafka-apis.png" style="width:500px;border:2px solid #C6C6C6;" >

kafka的内部客户端和服务器端的通信是通过简单，高效，跨语言的[TCP协议](https://kafka.apache.org/protocol.html)，该协议具有向下兼容旧版本的能力。我们提供了java的客户端库，也提供了一些[其他语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)的支持。

###    主题和数据日志(Topics and Logs)
首先让我们深入剖析kafka的核心抽象：**topic**。
一个topic代表一类数据记录的名称，kafka中的topic支持多订阅者的模式，也就是说订阅者可以是0个，1个，或者多个，这些订阅者订阅该topic中写入的数据。

而对于每个topic而言，kafka集群会将数据持久化到分区（partition）的日志文件中如图：
<img src="http://ou9e0q35h.bkt.clouddn.com/log_anatomy.png" style="width:500px;border:2px solid #C6C6C6;" >

如上图所示，每个分区的日志文件都是有序的，不可变的，只支持追加的方式（a structured commit log），每个分区里的记录都会标记一个唯一的id，这个id在各自分区中是唯一的，被叫做偏移量（offset ）。

不管kafka中的消息有没有被消费者消费掉，kafka都将会把生产者发布的消息持久化处理，保存到一个配置的期限。如果持久化策略设置的是2天，那么消息在发布后的两天内，消息是可以在次被消费的，2天之后，这部分消息将会被丢弃，这样以来，kafka能在大量数据量上面保持效率，kafka可以持久化数据一定长的时间。

<img src="http://ou9e0q35h.bkt.clouddn.com/log_consumer.png" style="width:500px;border:2px solid #C6C6C6;" >

事实上每个消费者（consumer）保存着消费情况的唯一元信息（消费者消费情况在这里成为元信息metadata），元信息的实现就是基于offset 或许说消费到数据日志的位置信息。消费者保存的这个offset 是消费者自己控制的，通常消费者会在读取记录后增加offset的数值，但因为消费的位置都是消费者自己控制的，所以消费者还可以按照自己想要的任意顺序来读取数据。举个例子，消费者可以重置一个已经消费过的offset这样它就能再次消费到以前已经消费过的数据，又或者消费者可以直接设置一个offset，这样它就能跳过前面的数据，而直接从目前设置的位置开始消费。

结合上面的这些特点，kafka的消费者是如此轻量的（原文说 very cheap，结合上下问，大概是说消费者简单，轻量级和独立），消费者的创建消费都不会影响到kafka集群，也不会影响到其他的消费者，比如你可以用命令行工具消费topic中的数据并不会影响到其他的消费者。

分区这种设计有很多优点，第一，如果topic不分区，那么topic会受到单台服务器的限制，但如果topic有多个分区，那么单独的分区会收到单个服务器的限制，这样也就提高了topic容量的扩展性(topic是可以动态添加分区的，节点也是可以动态添加的，所以可以很方便的扩容，这个是我个人插一句，原文这里没说)。第二，分区可以提高访问的并发性。

###    分布式(Distribution)
分区的数据日志分散存放在kafka集群的服务器中，每个服务器都处理分区共享的数据和请求（很难解释原文这段说的是什么屎，个人觉得好像是说每个服务器都会处理数据和请求，而这些数据和请求又看作是Partition整体的数据和请求）。每个Partition的数据又具有副本，副本是可配置的，并且是分布在不同的kafka服务器上的。
 
每个分区的副本都在不同的服务器上（这句是个人临时加的，便于理解），不会出现有一个分区的两个副本在同一个服务器上，有一个分区所在服务器作为分区的leader（主节点）,而其他的作为followers（从节点），可以有零个或者多个followers。leader会负责所有数据的读写请求，而followers作为leader的备用，如果leader所在服务器挂掉，那么其他的followers会选出新的leader。每个服务器上可以同时存在有一个分区的leader和另外一个分区的followers。这样可以达到负载均衡的作用（因为读写都是从leader，那么leader肯定尽量分布在各个服务器，leader的分布本身是透明的，kafka肯定内部有相应的算法实现，这个我们也不用太关心）。

###    生产者(Producers)
生产者发送消息到指定的topic中，生产者决定什么样的消息被分到什么样的区（消息的分区策略也是由生产者决定的），可以采用简单的轮转( round-robin)分发达到简单的负载均衡，或者通过自定义的语意分区的方法(比如按照消息的key）稍后介绍更多关于分区的用法。

###    消费者(Consumers)
消费者又会打上一个分组标签名（消费者会进行分组），每条数据是被组内其中一个消费者实例订阅。消费者事例是不同的进程，并且可以在不同的机器上。假如有n个消费者实例，如果这n个消费者都属于一个组，那么这个组订阅的topic中的消息将会均衡分发到这些消费者事例中，而每个消费者事例会消费部分消息。假如这n个消费者事例各自分为一组，那么每个消费者都会消费到其订阅topic中的所有消息。

<img src="http://ou9e0q35h.bkt.clouddn.com/consumer-groups.png" style="width:500px;border:2px solid #C6C6C6;" >

如上示意图，拥有两个kafka服务器的集群的一个topic拥有4个partition，拥有两组消费者组订阅，A组消费者组有两个消费者事例，B组拥有4个消费者实例。

通常情况下，一个topic拥有的订阅的消费者组数量并不多，而每个组独立的实现消费逻辑，互不影响。每个消费者组由可扩展，容错的消费者事例构成。这也仅仅是发布与订阅的模型，只不过这种模型中消费者也可以看作一个集群模式（一个消费者组算一个消费者集群cluster ），而不是单独独立的进程。

kafka内部实现的消费策略是将topic划分为多个partition，而对于一个partition而言，数据在同一时间被同一个消费组内唯一一个消费者消费(不会出现一个分区同时被同一个组的两个消费者共同消费【这段话读了太久，总算是明白了】)，反过来对于同组的一个消费者而言，它可以同时消费多个分区中的数据，而分区数据分配给消费者对消费者而言是相对均分(fair share)分配的。而消费者组内是通过kafka内部一种具有动态特性的协议来维护组员关系的，如果组内加入了新的消费者实例，那么新实例会动态从另外的消费者组员那里分得partition来进行消费（前提是另外这个消费者此时消费超过一个partition的数据【我加的，如果自己只负责消费一个组，还要把这个组让给别人从而使得自己空闲，这样新加的实例就毫无意义了】），反过来，如果组内有消费者实例死掉，那么它所负的那些partition将会分摊给其他的消费组员。

kafka只保证了每个分区中的消息是有序的，也就是只保证了每个分区中的offset有序，而同一个topic中的不同分区中的消息比较序列是没有意义的。保证分区内数据是有序的已经能够满足大多数应用的需求了，但是如果需要实现整个topic中的数据有序，那么只能将topic设置成一个分区，这就意味着，消费者这个topic的消费者组中仅仅有一个消费者实例在同一时间消费数据了（这种做法会大大减小了kafka的并行度）。

###    可靠性（Guarantees）

kafka作为具有高可靠性的特点，从下面几点说明：

- 消息发送到同一个topic partition的数据按发送的先后，后发送的会后被加入（appended ）。M1,M2做为两条消息被同一个生产者发送到同一个partition的情况下，M1先发送，那么M1的offset比M2的offset指小，M1的数据会在M2之前追加到数据日志中。
- 消费者见到数据的顺序是按照日志中数据存放的顺序来的。（前文中我们提过了，消费顺序可以有消费者自定义，通过设置消费的offset，但寻址的过程却只能按照日志存储数据的顺序）
- 对于一个拥有N个副本因子的topic而言，我们最多可以容忍该topic的N-1个分区所在服务器挂掉，在这N-1个服务器挂掉的情况下依然能保证该topic已经提交(committed)数据的完整性
